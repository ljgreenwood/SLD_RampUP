 So this is the ramp up that I've put together for SLD. It's a simple full stack app that takes in files from the user and then processes uses Flask in the Python backend to process that audio into a format that the whisper model that I have installed locally can then transcribe. And these are the settings that I have set up for it. So here's the backend of origin requests being used for any standard Flask backend. This is the reprocessing for the audio files. So essentially we're sending just one file right now to the backend and cleaning this file up at clean.wave because the model needs a waveform input. That's a 16 kHz sample rate and the mono channel. So that's up, we're using a FFmpeg and using sub process to do that. It's getting the audio from the path that's produced when you send the file to the backend. And there is some issues right now with processing empty segments of audio. So whenever it's just like dead silence in the track, it tries to caption it and that's not really accurate as I'll show in a second. There's just some formatting. I have a directory here that's logging all of the runs with the tokens, temperature, word start and end times, probability of classifying that token as the correct one. So that's essentially the backend. This is just, for some reason my computer needs this encoding for the URLs. I don't know if this is something I'm going to have to modify when we're boarding it to like an actual hosting. But for my machine, this is what works. So, yeah, it's basically the backend is the front end. I'm using file pond plugin just to make it easy because it has like a bunch of nice UI preexisting. A couple of use date variables just to keep track of like the current files that have been uploaded, the path to those files, the transcriptions. And then eventually this will be updated, the transcription index, so that you can have multiple transcriptions indexed in the file paths in the files array. And then essentially just like render based on like clicking through like the first transcription for the first file, then the second transcription, etc. And oh, the fuck, zoom crashed. Oh, that did. Okay. So, yeah, that's basically that. This is a handler that's handling the upload when you press the button. And then it's just going to make an async batch request in order to get the transcription and the post is going to be done in the backend. And the API call is going to be done in the backend. I'm using some logic with like whether the transcription button has been pressed, like whether it's a null type or an empty string or an actual value in order to do some like a loading logic in the front end. But all this stuff you'll see is not really that important. So I'll just run. If you run MPM run dev, it does a concurrently command for byte and the backend. So the backend should be running in a second. It takes a little bit to boot up. And this is the front end site. So, yeah, I'll just do an example. I have these meditation files that I've been using to test because they're pretty clear audio. So it's easy to like check the transcription. And so, yeah, that's kind of how that drag and drop works. I'll press transcribe and the backend, you'll see that this FM peg, FFM peg process is run in order to convert it to a waveform because what I uploaded was an MP3. Just wait. I'll see. It's like a 10 minute audio file. So it's honestly still pretty fast for how long that video file is. I'm assuming that a lot of these tests that we're going to be running with SLD are not going to be like 30 minute video, 30 minute audio files. But I mean, I think it can handle that. It's just going to take a while. But with the dead space segmentation, I think that can just be done without the model. You know, you can just like, we detect that there's these long portions of dead silence. You can just kind of cut that out of the transcription during pre-processing. So that'd probably be the best thing to do to mitigate some of these problems. Yeah, this is doing the transcription pretty well. It just shows up in the little window so you can view it. And then, this is like when it starts to go into the empty text area. So this is like the last portion. And I'll show you actually the run log. Once it gets to. Yeah, like the confidence is pretty, pretty high. Until you get to like. Yeah, the dead, the dead space is like it has no idea what it's what it's doing. So, it's just trying to caption it. Set up this environment here to have like, do not caption empty audio segments, but that didn't really work very well. So, let's see if there's more we can do than just product engineering there. But yeah, it's just kind of like keeps repeating. Which is a little scary. But in order to download, you just run this and then you have the text file for the entire thing. And that's how it works. There you go.